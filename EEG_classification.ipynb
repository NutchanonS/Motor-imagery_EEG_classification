{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAFcCHlwOObA"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout,BatchNormalization,SpatialDropout1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load data EEG signal\n",
        "(the data is filter 20 channels and label is already making one hot reference on min2net paper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMiP7XWMPAJH"
      },
      "outputs": [],
      "source": [
        "#Load your data\n",
        "x_all = np.load('X_all.npy')\n",
        "y_all = np.load('y_all.npy')\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_all, y_all,test_size=0.20,random_state=69)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBgGkVwCoyFg"
      },
      "source": [
        "# Yuchen-Wang-SH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY03RdNRocov",
        "outputId": "481ce25b-40d2-4388-b86f-793959160458"
      },
      "outputs": [],
      "source": [
        "# from src.models.PAMI import CNN_P300_PAMI\n",
        "# input_ch = len([7,8, 9, 10, 12, 13,14 ,17,18,19,20, 32,33 ,34,35,36,37,38,39,40])\n",
        "# model = CNN_P300_PAMI((400, input_ch,1))\n",
        "# model.summary()\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "import numpy as np\n",
        "def sigmoid_pami_p300(x):\n",
        "    return 1.7159 * K.tanh(2 * x / 3)\n",
        "def CNN_P300_PAMI(input_shape):\n",
        "    get_custom_objects().update({'custom_activation': layers.Activation(sigmoid_pami_p300)})\n",
        "\n",
        "    num_electrodes, points_to_slice = input_shape[1] , input_shape[0]\n",
        "    num_first_filter = 10\n",
        "    num_second_filter = 5 * num_first_filter\n",
        "\n",
        "    input_layer = layers.Input(input_shape)\n",
        "    conv_1 = layers.convolutional.Conv2D(filters=num_first_filter, kernel_size=[num_electrodes, 1], \n",
        "                                        strides=[1, 1], activation='linear')(input_layer)\n",
        "\n",
        "    conv_1_acti = layers.Activation(sigmoid_pami_p300)(conv_1)\n",
        "\n",
        "    conv_2 = layers.convolutional.Conv2D(filters=num_second_filter, kernel_size=[1, 13], \n",
        "                                        strides=[1, 13], activation='linear')(conv_1_acti)\n",
        "    conv_2_acti = layers.Activation(sigmoid_pami_p300)(conv_2)\n",
        "    flatten = layers.Flatten()(conv_2_acti)\n",
        "    fc = layers.Dense(100, activation='sigmoid')(flatten)\n",
        "    output_layer = layers.Dense(4, activation='sigmoid')(fc)\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "input_ch = len([7,8, 9, 10, 12, 13,14 ,17,18,19,20, 32,33 ,34,35,36,37,38,39,40])\n",
        "model = CNN_P300_PAMI((400, input_ch,1))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssH9wAMhg3KE",
        "outputId": "bc36d566-3653-422e-ebc2-4b9b35ec3c9f"
      },
      "outputs": [],
      "source": [
        "from src.models.PAMI import CNN_P300_PAMI\n",
        "import tensorflow as tf\n",
        "# model = CNN_P300_PAMI(train['signal'].shape[1:]) \n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "earlystopping = EarlyStopping(monitor = \"val_accuracy\",patience = 3)\n",
        "model.fit(x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2],1) , y_train, x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2],1), y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBXGxaSN-DF7"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Temporary_dataset/my_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN 1D model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout,BatchNormalization,SpatialDropout1D\n",
        "# Create sequential model \n",
        "cnn_model = tf.keras.models.Sequential()\n",
        "#Zero CNN layer  with 32 filters, conv window 3, relu activation and same padding\n",
        "cnn_model.add(Conv1D(filters=32, kernel_size=(20,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (400, 20)))\n",
        "cnn_model.add(BatchNormalization())\n",
        "#First CNN layer  with 32 filters, conv window 3, relu activation and same padding\n",
        "cnn_model.add(Conv1D(filters=32, kernel_size=(20,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(SpatialDropout1D(0.5))\n",
        "#Second CNN layer  with 64 filters, conv window 3, relu activation and same padding\n",
        "cnn_model.add(Conv1D(filters=32, kernel_size=(6,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
        "cnn_model.add(BatchNormalization())\n",
        "#Third CNN layer with Max pooling\n",
        "cnn_model.add(MaxPool1D(pool_size=(2,), strides=2, padding='same'))\n",
        "cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
        "cnn_model.add(SpatialDropout1D(0.5))\n",
        "#Flatten the output\n",
        "cnn_model.add(Flatten())\n",
        "#Add a dense layer with 296 neurons\n",
        "cnn_model.add(Dense(units = 296, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
        "#Add a dense layer with 148 neurons\n",
        "cnn_model.add(Dense(units = 148, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
        "#Add a dense layer with 74 neurons\n",
        "cnn_model.add(Dense(units = 74, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
        "\n",
        "#Softmax as last layer with five outputs\n",
        "cnn_model.add(Dense(units = 4, activation='softmax'))\n",
        "\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "cnn_model.compile(optimizer=optimizer, loss = loss, metrics=['accuracy'])\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "modelPath = os.path.join(os.getcwd(), 'bestModel.h5')\n",
        "checkpoint = ModelCheckpoint( # set model saving checkpoints\n",
        "    modelPath, # set path to save model weights\n",
        "    monitor='val_loss', # set monitor metrics\n",
        "    verbose=1, # set training verbosity\n",
        "    save_best_only=True, # set if want to save only best weights\n",
        "    save_weights_only=False, # set if you want to save only model weights\n",
        "    mode='auto', # set if save min or max in metrics\n",
        "    period=1 # interval between checkpoints\n",
        "    )\n",
        "\n",
        "earlystopping = EarlyStopping(\n",
        "    monitor='val_loss', # set monitor metrics\n",
        "    min_delta=0.001, # set minimum metrics delta\n",
        "    patience=4, # number of epochs to stop training\n",
        "    restore_best_weights=True, # set if use best weights or last weights\n",
        "    )\n",
        "callbacksList = [checkpoint, earlystopping] # build callbacks list\n",
        "\n",
        "cnn_model_history = cnn_model.fit(x_train, y_train, epochs=100, batch_size = 64, validation_data = (x_val, y_val), callbacks=callbacksList)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Submission kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP_Fm4NInmzf",
        "outputId": "c24a4451-ef81-45b3-9186-8f528ec86344"
      },
      "outputs": [],
      "source": [
        "xpred = xp_test[:,:,[7,8, 9, 10, 12, 13,14 ,17,18,19,20, 32,33 ,34,35,36,37,38,39,40]]\n",
        "xpred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX0hKM5T3lvP"
      },
      "outputs": [],
      "source": [
        "predict = model.predict(xpred.reshape(xpred.shape[0],1, xpred.shape[1], xpred.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C1mzVxM32dK",
        "outputId": "bfe52e86-5545-42bb-87df-a1dc9643a77f"
      },
      "outputs": [],
      "source": [
        "predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nms-rf3uBIvq",
        "outputId": "ae26ddd8-a44c-4e88-9a06-87f178d0c13e"
      },
      "outputs": [],
      "source": [
        "predict[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TkCzehz4NYs"
      },
      "outputs": [],
      "source": [
        "sub=[]\n",
        "for i in predict:\n",
        "  sub.append(np.argmax(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gHzxYvqLB-3k",
        "outputId": "705e2323-4b51-40c3-eacb-6f9ce3934d27"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "a=pd.read_csv('/content/sample_submission.csv')\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7b4__jxB4XZ"
      },
      "outputs": [],
      "source": [
        "num=[]\n",
        "for i in range(400):\n",
        "  num.append(i+1)\n",
        "for i in range(400):\n",
        "  num.append('f'+str(i+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HIVQYg9CyCQ"
      },
      "outputs": [],
      "source": [
        "for i in range(400):\n",
        "  sub.append(None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUHu3uj6BO9c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'sample_id':num , 'prediction':sub})\n",
        "df.to_csv('/content/submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "9FS1lYJRDImT",
        "outputId": "c51728d3-9849-47c8-ddf9-00cb8e3fc765"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8DAd3x273x2"
      },
      "source": [
        "# try preprocessing fast fourier transform (Not use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrUmJ_-LDUBy",
        "outputId": "31485060-217c-41b9-adcd-a1decc06a1ac"
      },
      "outputs": [],
      "source": [
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "f0dPuXkuDgoZ",
        "outputId": "141d1419-267e-4e41-ade8-1bcffb7c745a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft, fftfreq\n",
        "samplerate=100\n",
        "N=400\n",
        "xf = fftfreq(N,1/samplerate)\n",
        "xx = fft(x_all)\n",
        "plt.plot(xf,xx)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHKz1uVEE53V"
      },
      "outputs": [],
      "source": [
        "# 41600,400,400,20\n",
        "from scipy.fft import fft, fftfreq\n",
        "samplerate = 100 #hz\n",
        "duration = 4 #sec\n",
        "x_fft = []\n",
        "for i in x_all:\n",
        "  am = fft(i)\n",
        "  # f = fftfreq(samplerate*duration , 1/samplerate)\n",
        "  x_fft.append(am.tolist())\n",
        "x_fft = np.array(x_fft)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfE5dRtjwdNN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
